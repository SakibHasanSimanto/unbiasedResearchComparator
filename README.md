# ğŸ§  PaperRanker: An Unbiased Research Quality Comparison Tool

**PaperRanker** is a lightweight academic tool built with [Streamlit](https://streamlit.io/) that uses large language models (LLMs) to compare and analyze the scientific quality of two research worksâ€”*without considering author reputation, journal prestige, or citation count*. It treats all submissions as preprints and provides a fair evaluation purely based on content.

---

## âœ¨ Features

- ğŸ”¬ **Content-based Comparison Only** â€“ Ignores author/journal reputation, compares based on research contributions.
- ğŸ§¾ **Simple Interface** â€“ Users enter summaries or abstracts of two papers.
- ğŸ¤– **LLM-powered Judgement** â€“ Uses free-to-use LLMs via [Groq API](https://console.groq.com/).
- ğŸ§  **Optional Model Thinking** â€“ Displays or separates model "thought process" (like DeepSeek's `<think>` content).
- ğŸ”„ **Switchable LLMs** â€“ Choose from 4 high-performing models:
  - ğŸ¦™ LLaMA 3 (8B)
  - ğŸ“˜ Gemma 2 (9B)
  - ğŸ¤” DeepSeek LLaMA-70B (Recommended)
  - ğŸ§ª Mistral-SABA 24B (Terms acceptance required)

---

## ğŸš€ Demo

Live demo on GitHub-hosted Streamlit app (replace with your link):  
ğŸ“ https://unbiased-research-comparator.streamlit.app/ 

---

## ğŸ› ï¸ Tech Stack

- **Frontend:** [Streamlit](https://streamlit.io/)
- **Backend API:** [Groq LLM API](https://console.groq.com/)
- **Languages:** Python 3.10+
- **Model Options:** LLaMA3, Gemma2, DeepSeek, Mistral (via Groq)

---


